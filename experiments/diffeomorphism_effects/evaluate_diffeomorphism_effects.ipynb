{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "from data.toy_data.hyperbolic import hyperbolic\n",
    "from data.toy_data.circle import circle\n",
    "from data.toy_data.spiral import twospirals\n",
    "\n",
    "from src.diffeomorphisms.iresnet_euclidean_product import i_ResNet_into_Euclidean\n",
    "from src.manifolds.euclidean import Euclidean\n",
    "from src.manifolds.pull_back_manifold import PullBackManifold\n",
    "from src.riemannian_autoencoder import Curvature_Corrected_Riemannian_Autoencoder\n",
    "from src.riemannian_autoencoder.low_rank_approximation.naive_tsvd import naive_low_rank_approximation\n",
    "from src.utils.isomap import make_adjacency, get_path, isomap\n",
    "from src.utils.neural_network.distance_data_set import DistanceData\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(31)\n",
    "\n",
    "results_path = os.path.join(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "num_data = 51\n",
    "noise = 0.1\n",
    "\n",
    "# iresnet parameters\n",
    "s_nBlocks = 100 \n",
    "s_max_iter_inverse = 50\n",
    "s_int_features = 10 \n",
    "s_coeff = 0.8 \n",
    "s_n_power_iter = 10 \n",
    "\n",
    "# variational problem parameters\n",
    "alpha_sub = 10.\n",
    "alpha_iso = 1/100\n",
    "\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = twospirals(int((num_data-1)/2), noise=noise)\n",
    "s_data_manifold = twospirals(250, noise=0.)\n",
    "\n",
    "plt.plot(s_data[:,0], s_data[:,1], '.')\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"s_data.eps\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters\n",
    "trained_networks_path = os.path.join(\"models\", \"spiral\")\n",
    "s_z_path = os.path.join(trained_networks_path, \"z.pt\")\n",
    "s_O_path = os.path.join(trained_networks_path, \"O.pt\")\n",
    "\n",
    "# load s_offset and s_orthogonal\n",
    "s_offset = torch.load(s_z_path)\n",
    "s_orthogonal = torch.load(s_O_path)\n",
    "\n",
    "# load experiment-dependent pullback manifolds and losses\n",
    "s_M_dict = {}\n",
    "s_loss_progession_dict = {}\n",
    "figure_label_dict = {}\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        # load differomorphisms\n",
    "        s_phi_path = os.path.join(trained_networks_path, \n",
    "                                  \"i_resnet_euclidean_product_{}_blocks_{}_int_features_{}_epochs_{}_subspace_reg_{}_isometry_reg.pt\".format(\n",
    "                                      s_nBlocks, s_int_features, n_epochs, bool(i), bool(j))\n",
    "                                  )\n",
    "        s_diffeo = i_ResNet_into_Euclidean([1,1], s_offset, s_orthogonal, \n",
    "                          nBlocks=s_nBlocks, max_iter_inverse=s_max_iter_inverse, int_features=s_int_features, coeff=s_coeff, n_power_iter=s_n_power_iter) \n",
    "        s_diffeo.phi.load_state_dict(torch.load(s_phi_path))\n",
    "        s_M_dict[f\"{i}{j}\"] = PullBackManifold(s_diffeo)\n",
    "\n",
    "        s_loss_progression_path = os.path.join(trained_networks_path, \n",
    "                                  \"loss_progression_{}_blocks_{}_int_features_{}_epochs_{}_subspace_reg_{}_isometry_reg.pt\".format(\n",
    "                                      s_nBlocks, s_int_features, n_epochs, bool(i), bool(j))\n",
    "                                  )\n",
    "        s_loss_progession_dict[f\"{i}{j}\"] = torch.load(s_loss_progression_path)\n",
    "        \n",
    "        figure_label_dict[f\"{i}{j}\"] = r'$\\alpha_{\\mathrm{sub}}=$' +f'{i * alpha_sub}, ' + r'$\\alpha_{\\mathrm{iso}}=$' +f'{j * alpha_iso}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that network has actually converged\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        s_loss_progression = s_loss_progession_dict[f\"{i}{j}\"]\n",
    "\n",
    "        if i == j == 0:\n",
    "            plt.plot(torch.linspace(0., n_epochs, len(s_loss_progression)), s_loss_progression)\n",
    "        plt.plot(torch.linspace(0., n_epochs, len(s_loss_progression)), s_loss_progression, label=figure_label_dict[f\"{i}{j}\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_path,f\"loss_progressions_on_s_M.eps\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose special points\n",
    "s_z1 = s_data_manifold[0][None]\n",
    "s_z2 = s_data_manifold[-1][None]\n",
    "s_z3 = s_offset[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodesic interpolation\n",
    "s_data_gamma_12_t = twospirals(250, noise=0.)\n",
    "adjacent_distances = torch.norm(s_data_gamma_12_t[1:] - s_data_gamma_12_t[:-1], 2, -1)\n",
    "cumulative_distances = torch.cat((torch.zeros(1), torch.cumsum(adjacent_distances, 0)),0)\n",
    "t = cumulative_distances / cumulative_distances[-1]\n",
    "\n",
    "s_z1_var = s_z1 + 0.5 * torch.tensor([1.,0.])\n",
    "\n",
    "s_gamma_12_t_dict = {}\n",
    "error_12_t_dict = {}\n",
    "s_gamma_12_var_t_dict = {}\n",
    "error_12_var_t_dict = {}\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        s_M = s_M_dict[f\"{i}{j}\"]\n",
    "\n",
    "        # compute geodesics\n",
    "        s_gamma_12_t_dict[f\"{i}{j}\"] =  s_M.geodesic(s_z1, s_z2, t)\n",
    "\n",
    "        # compute error\n",
    "        error_12_t_dict[f\"{i}{j}\"] = torch.norm(s_gamma_12_t_dict[f\"{i}{j}\"] - s_data_gamma_12_t, 2, -1)\n",
    "\n",
    "        # compute geodesics variation\n",
    "        s_gamma_12_var_t_dict[f\"{i}{j}\"] =  s_M.geodesic(s_z1_var, s_z2, t)\n",
    "\n",
    "        # compute error wrt original geodesic\n",
    "        error_12_var_t_dict[f\"{i}{j}\"] = torch.norm(s_gamma_12_var_t_dict[f\"{i}{j}\"] - s_gamma_12_t_dict[f\"{i}{j}\"], 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot geodesics\n",
    "plt.plot(s_data[:,0], s_data[:,1], '.')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.plot(s_gamma_12_t_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,0], s_gamma_12_t_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,1], \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "        \n",
    "plt.plot(s_data_gamma_12_t[:,0], s_data_gamma_12_t[:,1], alpha=0.)\n",
    "plt.plot(s_data_gamma_12_t[:,0], s_data_gamma_12_t[:,1], \"--\", label=\"ground truth geodesic\")\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"geodesics_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "# plot geodesic variations\n",
    "plt.plot(s_data[:,0], s_data[:,1], '.')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.plot(s_gamma_12_var_t_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,0], s_gamma_12_var_t_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,1], \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "        \n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"geodesic_variations_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "# print errors\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        mean_error = torch.mean(error_12_t_dict[f\"{i}{j}\"])\n",
    "        std_error = torch.std(error_12_t_dict[f\"{i}{j}\"])\n",
    "        print(f\"average error = {mean_error.squeeze().detach().numpy()} \\pm {std_error.squeeze().detach().numpy()}\")\n",
    "\n",
    "        mean_var_error = torch.mean(error_12_var_t_dict[f\"{i}{j}\"])\n",
    "        std_var_error = torch.std(error_12_var_t_dict[f\"{i}{j}\"])\n",
    "        print(f\"average variation error = {mean_var_error.squeeze().detach().numpy()} \\pm {std_var_error.squeeze().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barycentre\n",
    "s_data_var = s_data + 0.25 * torch.randn((num_data, 2))\n",
    "# isometry_error = torch.mean(torch.norm(s_data_var - s_data, 2, -1))\n",
    "\n",
    "s_barycentre_dict = {}\n",
    "error_s_barycentre_dict = {}\n",
    "s_barycentre_var_dict = {}\n",
    "error_s_barycentre_var_dict = {}\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        s_M = s_M_dict[f\"{i}{j}\"]\n",
    "        \n",
    "        # compute barycentre\n",
    "        s_barycentre_dict[f\"{i}{j}\"] = s_M.barycentre(s_data[None])\n",
    "\n",
    "        # compute error\n",
    "        error_s_barycentre_dict[f\"{i}{j}\"] = torch.norm(s_barycentre_dict[f\"{i}{j}\"], 2, -1)\n",
    "\n",
    "        # compute geodesics variation\n",
    "        s_barycentre_var_dict[f\"{i}{j}\"] =  s_M.barycentre(s_data_var[None])\n",
    "\n",
    "        # compute error wrt original geodesic\n",
    "        error_s_barycentre_var_dict[f\"{i}{j}\"] = torch.norm(s_barycentre_var_dict[f\"{i}{j}\"] - s_barycentre_dict[f\"{i}{j}\"], 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot barycentre\n",
    "plt.plot(s_data[:,0], s_data[:,1], '.')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.plot(s_barycentre_dict[f\"{i}{j}\"][:,0].detach().numpy(), s_barycentre_dict[f\"{i}{j}\"][:,1].detach().numpy(), '.', \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"barycentre_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(s_data[:,0], s_data[:,1], '.')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.plot(s_barycentre_var_dict[f\"{i}{j}\"][:,0].detach().numpy(), s_barycentre_var_dict[f\"{i}{j}\"][:,1].detach().numpy(), '.', \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "\n",
    "plt.plot(s_data_var[:,0], s_data_var[:,1], '.')\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"barycentre_variation_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "# print errors\n",
    "# print(f\"error if perfect isometry = {isometry_error}\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        error = error_s_barycentre_dict[f\"{i}{j}\"]\n",
    "        print(f\"error = {error.squeeze().detach().numpy()}\")\n",
    "\n",
    "        var_error = error_s_barycentre_var_dict[f\"{i}{j}\"]\n",
    "        print(f\"average variation error = {var_error.squeeze().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute logs\n",
    "s_logs_dict = {}\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        s_M = s_M_dict[f\"{i}{j}\"]\n",
    "\n",
    "        # compute logs to all data\n",
    "        s_logs_dict[f\"{i}{j}\"] = s_M.log(s_z3 * torch.ones((num_data,1)), s_data[:,None])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot logs\n",
    "plt.plot(s_offset[0], s_offset[1], '.')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.plot(s_logs_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,0], s_logs_dict[f\"{i}{j}\"].squeeze().detach().numpy()[:,1], '.', \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"logs_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "# plot the logs of the fully diffeomorphisms trained with both subspace regularisation and isometry regularisation once more\n",
    "plt.plot(s_logs_dict[f\"{1}{1}\"].squeeze().detach().numpy()[:,0], s_logs_dict[f\"{1}{1}\"].squeeze().detach().numpy()[:,1], '.')\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"log_on_s_M.eps\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low rank approximation\n",
    "noisy_s_data = twospirals(250, noise=0.25)\n",
    "\n",
    "projected_s_mesh_dict = {}\n",
    "error_projected_s_mesh_dict = {}\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        s_M = s_M_dict[f\"{i}{j}\"]\n",
    "        s_z = s_z3\n",
    "\n",
    "        # construct CC-RAE from test data (without curvature correction, because all kappa=0)\n",
    "        # # i) compute logs to all test data\n",
    "        # s_logs = s_M.log(s_z * torch.ones((num_data,1)), s_data[:,None])[:,0]\n",
    "\n",
    "        # i) rank 1 approximation\n",
    "        s_R_z, s_U = naive_low_rank_approximation(s_M, s_z, s_data, 1)\n",
    "        s_w_z = s_R_z / s_M.norm(s_z, s_R_z[None])[:,None]\n",
    "\n",
    "        # ii) construct CC-RAE\n",
    "        s_rae_w_z = Curvature_Corrected_Riemannian_Autoencoder(s_M, s_z, s_w_z)\n",
    "\n",
    "        # project noisy validation data onto manifold with RAE\n",
    "        projected_s_mesh_dict[f\"{i}{j}\"] = s_rae_w_z.project_on_manifold(noisy_s_data)\n",
    "\n",
    "        # compute error\n",
    "        error_projected_s_mesh_dict[f\"{i}{j}\"] = torch.norm(projected_s_mesh_dict[f\"{i}{j}\"] - noisy_s_data, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rae projections\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        if i == j == 0:\n",
    "            plt.plot(projected_s_mesh_dict[f\"{i}{j}\"].cpu().detach().numpy()[:,0], projected_s_mesh_dict[f\"{i}{j}\"].cpu().detach().numpy()[:,1], '.')\n",
    "        plt.plot(projected_s_mesh_dict[f\"{i}{j}\"].cpu().detach().numpy()[:,0], projected_s_mesh_dict[f\"{i}{j}\"].cpu().detach().numpy()[:,1], '.', \n",
    "                 label=figure_label_dict[f\"{i}{j}\"])\n",
    "\n",
    "plt.plot(noisy_s_data[:,0], noisy_s_data[:,1], '.')\n",
    "plt.plot(s_data_manifold[:,0], s_data_manifold[:,1], \"--\", label=\"ground truth manifold\")\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.savefig(os.path.join(results_path,f\"rae_projections_on_s_M.eps\"))\n",
    "plt.show()\n",
    "\n",
    "# print errors\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        mean_rae_error = torch.mean(error_projected_s_mesh_dict[f\"{i}{j}\"])\n",
    "        std_rae_error = torch.std(error_projected_s_mesh_dict[f\"{i}{j}\"])\n",
    "        print(f\"average error = {mean_rae_error.squeeze().detach().numpy()} \\pm {std_rae_error.squeeze().detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}